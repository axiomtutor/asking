<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>Stats Concepts - BPISTATS</title>
    <script id="MathJax-script" async src="../../MathJax-master/es5/tex-chtml.js">
    </script>
  </head>
  <body>
    <h1>Concepts in Statistics</h1>
    <p>Here we'll discuss some of the first important ideas of statistics so that you can warm up to them early.  If all goes well, when you encounter these ideas in class everything will go more smoothly and quickly because you've seen them once before.</p>
    <h1>Sampling concepts</h1>
    <p>In this section we'll talk about concepts related to gathering data.</p>
    <h2>Population versus sample</h2>
    <p>If the world were perfect we wouldn't need statistics.  How many people will vote for a given candidate?  If we could ask every single voter, there would be no need for statistics.  We would simply count the votes right away.  But we can't ask every voter because we would have to look up their phone numbers, or for the ones who can't be reached by phone, we'd have to find out where they live and go to them.  All of that costs too much money.</p>
    <p>Instead of just collecting ALL the data, statistics tells us how to only look at a portion of the data.  Suppose we want to know if the number of hours of sleep correlates with the GPA of students.  Rather than studying all of the millions of students in the world, we can simply take a sample of maybe 30 or 100 students.  As long as we randomly select these students, they should be similar to all other students.</p>
    <p>So here is the first important concept: The <b>population</b> of study is the TOTAL set of all individuals we're trying to understand.  A <b>sample</b> is a subset of the population that we will use to learn about the population.  In the student example above, the population is the set of all students throughout the world, and perhaps even throughout all of time.  The sample is the random 30 or 100 students chosen to represent the population.</p>
    <h3>Test your understanding</h3>
    <p>In the following, state which is the populaton and which is the sample.
    <ol>
      <li>Nielson devices are attached to about 5000 TVs in the US.  They are trying to find out what people are watching in the US.</li>
      <li>A company produces pill capsules and the thickness of the wall of the capsule needs to be between 0.5 and 1 millimeter.  To check whether their pill capsules are within this range they collect 100 pill capsules from the manufacturing line and measure them.</li>
    </ol></p>
    <h2>Bias</h2>
    <p>The idea of selecting a "representative" sample is a great cost-saving strategy.  But you have to use it carefully.  Imagine you want to know who will win the presidential election, so you go outside and ask the first ten people you see "Who are you voting for?"  If you live in New York City probably 9 in 10 people will tell you the Democrat (even if only 8 of those 10 will actually vote for the Democrat).  If you live in Riverton, Wyoming, probably 9 in 10 will tell you the Republican.  </p>
    <p>The reason is that your sample was not collected randomly.  By collecting your sample within a certain region, you made it more likely to get certain individuals.  If you wanted a true representation of the whole US voting trend, you would need to choose people from the US <i>at random</i>, and everyone would need to have the same probability of being selected. </p>
    <p>A method of collecting your sample is called <b>biased</b> if over-represents some members of the population.  There is a particular sampling method that is guaranteed to be unbiased: Simple Random Sample or SRS for short.  The way you do SRS is to first assign a number to every single member of the population.  For instance, in the student example, you could assign a number to every single student in the world.  Then use a random number generator to select a student at random.  Then do it again and again until you've selected the number of students you want.</p>
    <h3>Test your understanding</h3>
    <p>For the following, say whether the sampling method could be biased.  If it could be, indicate how you would conduct an SRS instead.
      <ol>
      <li>You want to measure how many teenagers in New York City use illegal drugs, so you study students from a few different high schools in the city.</li>
      <li>You want to study the rate of infidelity in people's marriages, so you randomly select some names from the phone book and ask them if they've ever cheated in their marriage.</li>
      <li>You want to study rates of diabetes and so you select a group of patients at a local hospital.</li>
    </ol></p>
    <h3>Answers</h3>
    <p>
      <ol>
        <li>This is biased because kids using illegal drugs are less likely to be in school.  To conduct an SRS you would somehow need to get the names of every student in the city, assign them numbers, and use a computer (or some other device) to randomly select a number from the set.</li>
        <li>This is biased because people will definitely lie about a sensitive question like this.  Here the bias isn't in the selection of the individuals but it is biased in how you get the answers from the individuals.  To perform an SRS you would need to have a guarantee that the individual's answers would never be connected back to them.  Say you make an online form where people can type in their answer and submit anonymously.</li>
        <li>This is biased because hospitals are likely to have people there to treat their diabetes, so you're going to get an over-representation of people with diabetes.  Since you're trying to study the population of all people (or maybe all US people?) you'll need to assign every US resident a number and randomly select that number.</li>
      </ol>
    </p>
    <h2>Convenience Sampling</h2>
    <p>
      The great thing about a well-built SRS is that it's guaranteed not to be biased.  The down-side is that you have to somehow be able to "assign every member of the population a number" and then you have to be able to go study any person you randomly select.  Often that is almost as hard and expensive as just studying the entire population.  How do you get the names and locations of every person in the US, so that you can assign them a number and then go study them.  Are you really going to find out that Buckey Finkleberg lives in Klamath Falls, Oregon as well as every other individual in the US?  Where are you going to get that information?  Once you get it, if you're trying to study their financial activities, how are you going to get that information?
    </p>
    <p>
      So SRS isn't really possible for large and difficult populations.  Therefore we need some more doable sampling methods even if they have a little more risk of bias.  The <i>WORST</i> of these is a so-called <b>convenience sample</b> because it is often SO biased that it really isn't worth doing.  But it is very cheap.  You just grab the nearest people around you and sample them.  It is depressing how often researchers actually do this. One researcher found that about 68% of psychology research subjects were college students.  
    </p>
    <p>Besides SRS and conveninece sampling there are other sampling methods (cluster, probability-proportional-to-size, and so on) but you don't need to know these right now.  The important point is that SRS is the best but it can be too difficult; convenience sampling is the worst but easiest.</p>
    <h2>Sample Size and Stratefied Sampling</h2>
    <p>Bias isn't the only problem you can have with a sample.  One issue can be sample size.  Suppose you want to know the average income in the United States.  And somehow you got a list of all the names of every person in the United States.  So you grab one at random, and find out that this person has an income of $40,000.  So you declare that the average income in the US is about $40,000.  I mean, that <i>might</i> be true, but the sample size is so small (the size is 1) that it's hard to really trust it.</p>
    <p>Sometimes we are interested in the relationships between groups.  For one example, maybe we want to look at the pay difference between men and women.  Then it might make sense to "stratefy" the population into subgroups, that is to say, do a random sample of the men and then do a random sample of the women.  This guarantees that we get a good sample size for each group.  This kind of sample design is called a <b>stratefied sample</b>. For another example, suppose you want to see how high school kids are different based on their grade levels.  So you group the freshmen, sophomores, juniors, and seniors, and sample each group separately to make sure you get a good number of samples from each group.</p>
    <p>This doesn't really do anything for bias.  It's just to make sure that the different groups are each sampled enough to get useful information.</p>
    <h2>Observation versus experiment</h2>
    <p>Science is based on observations and experiments, but they are very importantly different.  Observations are merely looking at what's happening.  For example, you can observe electrical phenomena when you observe lightening, or if you touch a door knob and it shocks your fingers.  </p>
    <p>But to really understand how electricity works, you need to do experiments.  Experiments aren't merely observing something, but actually acting on a system to see how it works.  If you rub a balloon on your hair it will eventually build up electrical charge.  </p>
    <p>Similarly in statistics, if you merely observe statistical records that can give you some informaiton.  But often you learn more in a laboratory setting where you are able to change one thing.  Take for example, administering a drug to lower bodyweight.  If you merely observe the people who take the drug, there could be many important factors that affect the outcome.  For one thing, people who choose to take the drug are people motivated and active enough to seek out the drug.  They might also be the people with enough money to afford the drug, if it's expensive.  All of these "factors" can be correlated to whether the person actually loses weight.  But you don't want to know about those factors, you just want to know whether the drug causes weightloss.  </p>
    <p>These other factors that could be correlated with the results are called <b>confounding factors</b>.  They are the factors you want to get rid of.  The variables that you're interested in here are (1) taking the drug and (2) whether weightloss occurs.  (1) is called the <b>independent variable</b> because you can control it, so it doesn't depend on anything else.  (2) is called the <b>dependent variable</b> because it depends on whether you take the drug or not.</p>
    <p>Instead of mere observation, which can have confounding variables, you should conduct an experiment where you are able to make a random selection of drug treatment subjects.  By choosing the subjects at random, you make sure that race, income, gender, personality differences, and other confounding variables definitely aren't related to the weightloss results that you will study.  For some of the subjects in your study, you assign them to a <b>control group</b>, which is the group of people who are not given the drug.  The others are assigned to a <b>treatment group</b>, who are given the drug.  It is important that the separation into control and treatment groups is ALSO done randomly, otherwise you might introduce bias.</p>
    <p>Once you have studied the drug using the experiment, it is much more plausible to say whether the drug <b>causes</b> weightloss or not.  Causation is a hugely important idea in science ... in fact, it might be the only question in science.  What things cause which other things?  That is kind of the whole universal question.  Observational studies usually aren't able to tell us causal information, but experiments can, because we can control for confounding varaibles.</p>
    <h2>Placebo and double-blind studies</h2>
    <p>In order for experiments to be done well, however, we need to be careful.  There is an effect that can confuse experimental results, called the <b>placebo</b> effect.  Perhaps when you administer the drug in the experiment, people feel optimistic about losing weight, and because of their good feelings they start moving around and eating healthier foods.  Then they start losing weight, but <i>not because of the drug</i>.  They're just losing weight because they're feeling better, and because of that they're doing healthier things.</p>
    <p>The placebo effect has been observed repeatedly in many studies, and it has caused us to think some treatments work when they don't.  Don't believe me?  Think that just feeling different can't make that big of a change in your health or weightloss?  I don't have any data about weightloss specifically but in a test for a headache cure, people given "sugar pill" still reported their headache going away.  We've also seen examples where pain, insomnia, cancer side-effects like naussea, and anxiety have been "cured" by "treatments" that actually don't do anything.</p>
    <p>So when you give a person a drug, how can you know that it's actually the drug that's causing weightloss?  How do you know that just any pill wouldn't cause the same amount of weightloss?  The answer is, rather than just giving the treatment group the drug, we also give the control group a sugar pill.  This is called a <b>single-blind</b> study because the purpose is to make the subject unaware of whether they're in the treatment or control group.  In that sense, they are "blind" to the study design.</p>
    <p>However, that may not fix everything.  Sometimes the doctors will treat the control group and the treatment group differently, even if they're not trying to.  They might ask the treatment group more questions, or study them more closely, or even just talk to them in very subtly different ways.  From that, people might realize that they're in the placebo control group, and then the placebo will be less effective.  And now we're back to not being able to tell how much better our drug is than mere placebo.</p>
    <p>So how do we control for that problem?  The answer is a <b>dobule-blind</b> study.  In a double-blind study, even the doctors administering the drugs don't know which is the control and which is the treatment.  Someone else is keeping track of that, but this person isn't allowed to interact at all with the subjects.  That person gives the doctor the drug or the placebo, and the doctor gives the pill to the assigned subject.  If even the doctor doesn't know which is which, she can't possibly treat the groups differently and disrupt the placebo effect.</p>
    <h2>Case control</h2>
    <p>We talked about how experiments can prove causation, because it allows us to control for variables.  And we discussed how the placebo effect can interfere with the validity of experiments.  But also, it is sometimes (but very rarely!) possible to use observational studies to get causal results.  The idea is that the observations must have some way of guaranteeing that there are no confounding factors.  That way, even if it's not a person who is controlling for the control group and the treatment group, there is some kind of natural process that is controlling the groups for us.  This very rarely happens, but when it does we are justified in drawing causal results from the study.  When this happens we call it a <b>case-control study</b>.  When you are deciding whether a particular study is a case-control study, you always have to ask if the separation of people into control and treatment groups really was random.  If the separation was truly random, then it is a case-control study.</p>
    <h2>Parameter veruss statistic</h2>
    <p>In the above, we have seen many examples of how we want to study a population, but instead are forced to study a sample in order to try to learn about the population.  In each case, the thing we want to learn about the population is called a <b>parameter</b>.  If you want to know the effectiveness of a weightloss drug, then you could say that the parameter is the numerical amount of weight the average person loses because they took the drug.  If you want to know the proportion of people who will vote for a candidate, this numerical value of the population is the parameter.  This is contrasted with the numerical values that you find in the sample, which we call a <b>statistic</b>.  If the average person in your study loses a certain amount of weight, that is the statistic, and you hope that it is close to how much a person in the population would lose if they took the drug.</p>
    <p>The statistic is almost never equal to the parameter, but we hope that the statistic is close.  If the average person in the study loses 10 pounds, then maybe the average person in the population loses 9 or 11 pounds.  But if the study were conducted rigorously, we hope that the true number of pounds a person in the population loses isn't 0 or 1.  </p>
    <p>But there are two different kinds of ways that a statistic can be wrong.  We've already talked about bias in samples.  A biased sample will always over-report or under-report some number.  Recall, if you're in New York and you ask the first 10 people you see who they're voting for, you're going to over-represent the number of Democratic voters.  We could also view this as a biased statistic because the statistic is much more likely to give a value which is higher than the population parameter.  Maybe 50% of Americans will vote Democrat but our statistic is that 90% of those sampled say they'll vote Democrat.  That's a highly biased statistic.</p>
    <p>But we've also seen another kind of error, which is called <b>variance</b>.  A statistic might not be biased in one direction or another, and yet still often be far from the true population parameter.  Recall the income example where you just randomly sample a single person from the country and ask their income.  There is no reason you would, on average, get someone over or under the average income in the US, so this isn't biased.  Yet it has a lot of variance because you might get someone with $0 annual income or you might get someone with $1 billion.  </p>
    <p>Think of it like shooting at a target.  If you have a tight cluster of bullets that are above the bullseye that's high bias and low variance.  If your bullets are spread far out, but still on average centered around the bullseye, then that's low bias and high variance.</p>
    <h1>Concepts of statistics from samples</h1>
    <h2>Point and interval estimates</h2>
    <p>One kind of statistic that we've now seen a lot of is a <b>point-estimate</b>.  That would be like taking a sample of 100 people and finding out how tall they are, in order to investigate how tall the average person is.  You might find that the average height is 5'9''.  That's what we call a point-estimate because it just reports a single value.  It's a good estimate if you can only pick a single number.  But it might be more informative to give a range of values, so that you can indicate not just what the average is, but how much variation there tends to be.  Of course you could say that the average is 5'9'' with a minimum of something like 4' and a maximum of something like 7'.  But minimums and maximums are very far from most people, so that's less helpful.</p>
    <p>What is significantly more helpful is to give an interval where, say, 80% of the population falls inside of that interval.  After a quick Google search I found that 80% of US males are between 5'5'' and 6'1''.  This is called an <b>interval estimate</b>.</p>
    <p>The center of this interval is about 5'8.  The difference between the center and one of the end-points is about 3''.  We call this the <b>margine of error</b>.  So the margin of error is the difference between the center of the interval and one of the end-points.  The <b>width</b> of the interval is twice as big as the margin of error and is the same thing as the difference between the end-points.</p>
    <h2>Frequency tables</h2>
    <p>Statistics are often things we use to summarize large data sets.  If you compute the average height of people in a sample, you lose a lot of information.  For instance, you lose information about the number of people who are shorter than 5' and you lose the number of people between 6'0'' and 6'3''.  Even an interval estimate doesn't keep all the information.  </p>
    <p>One way of summarizing information so that it's readable but keeps a lot more of the details, is to use a <b>frequency table</b>.  This is especially useful when your data comes in categories.  Say that you're studying the grades that students in a class get.  Rather than list out all of the grades, like B,A,B,B,C,B,C,A,A,C,C,C,B,A,... and so on, you might just summarize it in a frequency table like this:</p>
    
    $$
    \begin{array}{|c|c|}\hline
      A & 12\\
      B & 25\\
      C & 20\\
      D & 5\\
      F & 1\\\hline
    \end{array}
    $$
    
    <p>This shows, for instance, that the number of people who got a D grade is 5.  If we want to know the number of people who got less than an A we could add 25+20+5+1 = 51.  If we want to know how many people got between a B and a D we could add 25+20+5 = 50.  However, especially for very long frequency tables, there is a better way to display the information.  We can instead use a <b>cummulative frequency table</b>.  </p>
    
    $$
    \begin{array}{|c|c|}\hline
      A & 12\\
      B\geq & 37\\
      C\geq & 57\\
      D\geq & 62\\
      F\geq & 63\\\hline
    \end{array}
    $$
    
    <p>This table displays exactly the same information as the frequency table did.  We still see that the number of people who scored an A is 12.  We see that the number of people who scored a B or greater is 37, which is the same as in the frequency table.  If you want to know exactly how many people scored a B, that's 37-12 = 25.  </p>
    <p>However, this display makes it easier to compute ranges.  How many scored between a B and a D?  62-37.  Rather than compute long sums, you can always just compute a single difference.</p>
    <h2>Data types</h2>
    <p>One difference between the heights example and the grades example is that heights was entirely quantitative.  The difference between a 4' tall person and a 5' person is exactly the same difference as between a 5' tall person and a 6' tall person.  However, is the difference between an A and a B really the same as the difference between a D and an F?  Probably not: An A looks really goot but both the A and the B student pass the class.  The D student probably still passes while the F doesn't.  That makes the grades not <b>quantitative</b> but rather <b>qualitative</b>.</p>
    <p>If we tried to do a frequency table with quantitative data, like heights, we would have to do it differently.  How many people are exactly 5'0''?  How many people are 5'0.1''?  How many people are 5'0.00001''?  We can go out to very precise decimal values of inches and eventually find that nobody is EXACTLY that height.  If we were to put all these tiny decimal values int he table, the table would be huge and unreadable.  Therefore it would make more sense to <b>bin</b> people of similar heights together.  A natural way to do this would be to group together all people of height between 5'0'' and 5'1''.  Then we could make a frequency table that looks like this:</p>
    
    $$
    \begin{array}{|c|c|}\hline
      5'0''-5'1'' & 5\\
      5'1''-5'2'' & 4\\
      5'2''-5'3'' & 6\\
      ... & ... \\\hline
    \end{array}
    $$
    
    Of course I'm showing fake data for a sample of the population, and even doing it like this the table would be very long, since it has a row for every inch difference.  You could make the table shorter by increasing the bin width.  
    <h2>Graphical display</h2>
    <p>Although the frequency table helped us to quickly read a large data set, we still ran into some problems.  They could be smoothed over by plotting the frequency table as a bar graph.  A pie chart is another (but less good) graphical display of data.  However, in all cases a graphical display of data should have <i>lots of information in the title, axes, and legend</i>.  Make sure that anyone looking at the graph, with very little context or background, can understand what it's saying.</p>
    <p>As a slight piece of nomenclature, a <b>histogram</b> is the same thing as a bar chart except that the values on the horizontal axis are not qualitative data but instead are quantitative.</p>
  </body>
</html>

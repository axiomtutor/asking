<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Notes - Rudin Principles Ch3</title>
    <script src="https://d3js.org/d3.v5.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="../notes.css">
  </head>
  <body>
    <h1>Chapter 3</h1>
    <h1>Numerical Sequences and Series</h1>

    <h2>Section 1</h2>
    <h2>Convergent Sequences</h2>

    <div>
      <p>
        A sequence \(\{p_n\}\) is said to <b>converge</b> if there is a point \(p\in X\) such that \((\forall \varepsilon\in \mathbb R^+) (\exists N\in \mathbb Z^+) (\forall n\in \mathbb{Z}^+, n \geq N)( d(p_n,p) < \varepsilon)\).  We write either \(p_n\rightarrow p\) or \(\displaystyle \lim_{n\rightarrow \infty}p_n = p\).
      </p>
      <h3>Theorem: A sequence converges to a point if and only if every neighborhood of the point excludes only finitely many points in the sequence.  Limits are unique.  Convergence implies bounded.  Limit points of sets have sequences converging to the point, with the sequence in the set.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> Proving the first sentence, we assume a sequence converges.  Then for each neighborhood with a given radius, there exists a corresponding <i>N</i>.  By definition only the terms before this could be outside the neighborhood.  For the reverse direction, the argument is similar.
        </p>
        <p>
          <i>That limits are unique:</i> Take any two limits and show that their distance from each other is smaller than every positive \(\varepsilon\).  To do this, find an <i>N</i> corresponding to \(\varepsilon/2\) for each limit point and use the triangle inequality.
        </p>
        <p>
          <i>That convergence implies bounded:</i> Use \(\varepsilon = 1\).  The terms after this are all less than \(p+\varepsilon\), thinking of a positive example (negatives are handled just as easily).  Terms before it are finite and must have a max.
        </p>
        <p>
          <i>That limit points of sets have a sequence in the set which converges to it:</i> Take a neighborhood, pick a point, take a smaller neighborhood ... Construct your sequence this way.
        </p>
      </div>
      <h3>Theorem: If individual limits exist then limits are linear, distribute over multiplication, and into denominators (except limit 0).</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> For distributing over sums, pick \(\varepsilon/2\) and use the triangle inequality.  For distributing over constants, use \(\varepsilon/c\).  Distributing over products is harder, so we focus on that.
        </p>
        <p>
          <i>That limits distribute over products:</i> Wiggle into \(|s_nt_n - st|\) the term \(s_nt\).  Then we need a bound on <i>n</i> which guarantees

          $$ |s_nt_n - s_nt + s_nt t_n - st| < \varepsilon $$
        </p>
        <p>
          Use the triangle inequality

          $$ |s_n t_n - s_n t + s_n t - st| \leq |s_nt_n - s_n t| + |s_n t - st| $$
          $$ = |s_n||t_n-t| + |t||s_n-s| $$
        </p>
        <p>
          Now we can easily get a bound on the right-hand term because <i>t</i> is fixed.  We can enforce a condition on the <i>s</i>'s in terms of \(\varepsilon\) and <i>t</i>.  The tricky part is the left-hand term because \(|s_n|\) is not fixed, it's a function of <i>n</i>.  When using the convergence of \(s_n\) we always need bounds that are constant in <i>n</i>.
        </p>
        <p>
          So the trick is to round it up to its maximum, since we already know it's bounded.
        </p>
        <p>
          <i>That limits distribute to the denominator: </i> We need to show \(\Big| \frac 1 {s_n}  - \frac 1 s \Big| < \varepsilon\).

          $$ \Big| \frac{1}{s_n} - \frac 1 s \Big| = \Big| \frac{s-s_n}{ss_n}\Big| $$

          And since the numerator can be bounded, that part is easy.  And the <i>s</i> in the denominator is constant, so not a worry.  But again the \(s_n\) is a cause for concern but this time it's in the denominator.  And rounding up to the upper bound won't help since it moves the inequality in the wrong direction.
        </p>
        <p>
          But actually it is somewhat clear that these old strategies won't work this time.  We need to use the assumption that the limit is not zero.  So find an <i>N</i> such that the sequence stays far enough away from zero.  For specificity, let <i>N</i> be such that \((\forall n\geq N)(|p_n-p| < p/2) \).  This again assumes <i>p > 0</i> but the proof for a negative <i>p</i> is very similar.  What we're effectively doing here is just choosing the half-way point between 0 and <i>p</i>.  With all the terms staying inside that region, we can then replace \(p_n\) with the lower bound <i>p/2</i>.
        </p>
      </div>
      <div>
        <h3>Theorem: Vector sequences converge if and only if each coordinate does.  They also obey distribution in sums and dot-products.  Also if \(\vec x_n \rightarrow \vec x, \beta_n \rightarrow \beta\) then \(\displaystyle \lim_{n\rightarrow \infty} \beta_n\vec x_n = \beta\vec x\).</h3>
        <div class="sol">
          <p>
            <i>Explanation: </i> If every coordinate convergences, then to make \(|\vec x_n - \vec x | < \varepsilon \) that means we need

            $$ \sqrt{(x_{1,n}-x_1)^2 + \dots + (x_{n,n}-x_n)^2} < \varepsilon $$
          </p>
          <p>
            We want to do a term-by-term rounding up of the LHS, and we want to replace each \(x_{i,n}-x_i\) by \(\varepsilon\) or at least something close (maybe divided by <i>n</i>, or after toying with that it might be even better to use \(\sqrt n\).)  Lucky for us the assumption is just right for this sort of thing.
          </p>
          <p>
            To go in the other direction is even easier just because the absolute value of any coordinate is always smaller than the absolute value of a vector.
          </p>
          <p>
            This then allows us to easily prove the rest coordinate-wise.
          </p>
        </div>
      </div>
      <div>
        <p>
          A <b>subsequence</b> is any in-order subset of the sequence.  If a subsequence has a limit we call it at subsequential limit of the larger sequence.
        </p>
        <h3>Theorem: Sequences in compact sets always have a subsequential limit in the set. Every bounded sequence in has a subsequential limit.</h3>
        <div class="sol">
          <p>
            <i>Explanation: </i> There are two important parts of this claim.  First, these sequences always have subsequential limits.  Second, that the limit is in the set.  Boundedness would already be enough to guarantee that the sequence has some subsequential limit.  Closedness guarantees that the set contains its limit points.
          </p>
          <p>
            First notice that, as soon as the first part is done we can quickly handle the second by embedding any bounded set in a <i>k</i>-cell.
          </p>
          <p>
            Now to prove the first part, we consider whether the sequence visits finitely or infinitely many points.  If it's finite the matter is trivial: Some point must be visited infinitely often since there are infinitely many indices.
          </p>
          <p>
            If it visits infinitely many points, then this sounds too much like previous theorems about infinite subsets and compactness.  Once you obtain a limit point it is easy to use it to construct a sequence approaching it.
          </p>
        </div>
      </div>
      <div>
        <h3>Theorem: The set of subsequential limits of a sequence is closed.</h3>
        <div class="sol">
          <p>
            <i>Explanation: </i> The proof is direct from the definition of closed.  We select a point in the set and show that it is a limit point.  We have to care for some details, but the essentil plan is to form a sequence of neighborhoods around the point which shrink to zero, picking elements of the sequence along the way.
          </p>
        </div>
      </div>
    </div>
    <h2>Section 2</h2>
    <h2>Cauchy Sequences</h2>
    <div>
      <p>
        A sequence is <b>Cauchy</b> if \((\forall \varepsilon\in\mathbb R^+)(\exists N\in \mathbb Z^+)(\forall n\in \mathbb Z^+,n\geq N)(d(p_n,p_m)< \varepsilon)\).  This effectively means the points get infinitely close to each other.
      </p>
      <p>
        We call the <b>diameter</b> the sup over all the distances in a set.  Viwewed geometrically in the plane it's like taking the smallest circle that encompasses all the points, and using its diameter.
      </p>
      <p>
        Unpacking definitions it is not a hard proof that a sequence is Cauchy if and only if the limit of the truncated sequence diameters goes to 0.  Said formally, a sequence is Cauchy if and only if

        $$ \displaystyle \lim_{N\rightarrow \infty} diam E_N = 0 $$

        where \(E_N\)  is the set of all points in the sequence after index <i>N</i>.
      </p>
      <div>
        <h3>Theorem: Taking the closure of a set doesn't change its diameter.  Any descending chain of compact sets with diameter approaching 0 consists of exactly one point.</h3>
        <div class="sol">
          <p>
              <i>Expalantion: </i> It's clear that adding more points can only increase the diameter, i.e. \( diam E \leq  diam \overline E\).  To prove the other direction, we take any two points in the closure and show and show that their distance cannot be more than diam<i>E</i>.  
          </p>
        </div>
      </div>
    </div>






























  </body>
</html>

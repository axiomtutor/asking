<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Notes - Rudin Principles Ch6</title>
    <script src="https://d3js.org/d3.v5.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="../../../css/notes.css">
  </head>
  <body>
    <h1>Chapter 6</h1>
    <h1>The Riemann-Stieltjes Integral</h1>

    <h2>Section 1</h2>
    <h2>Definition and Existence</h2>

    <div>
      <p>
        Riemann defined the definite integral in terms familiar from a typical calculus course, with partitions of the <i>x</i>-axis of equal size.  We start with a more general notion of a partition:  For us a <b>partition</b> <i>P</i> of <i>[a,b]</i> is a finite set of points, <i>a = x<sub>0</sub> &leq; x<sub>1</sub> &leq; ... &leq; x<sub>n</sub> = b</i>.  We write <i>&Delta;x<sub>i</sub> = x<sub>i</sub>-x<sub>i-1</sub></i>.  We then define the <b>upper sum</b> to be

        $$ U(P,f) = \sum_{i=1}^n \left(\sup_{x_{i-1}\leq x\leq x_i}f(x)\right)\Delta x_i $$

        and similarly for the <b>lower sum</b>.  We then define the <b>upper Riemann integral</b> to be

        $$ \overline{\int_{a}^b}f(x)\ dx = \inf_{P}U(P,f) $$

        and similarly for the <b>lower Riemann integral</b>.  When the integrals agree we say that simply is the <b>Riemann integral</b>,

        $$ \overline{\int_a^b}f(x) \ dx = \underline{\int_a^b}f(x) \ dx = \int_a^b f(x) \ dx $$

        and when this is the case we say that <i>f</i> is <b>Riemann integrable</b> and write <i>f &in; &#x211C;</i>.
      </p>
      <p>
        As a note, throughly this section we assume the caveat that <i>f</i> is bounded on relevant invervals, which implies the existence of the suprema and infima mentioned.
      </p>
      <p>
        If <i>f</i> is bounded with <i>m &leq; f(x) &leq; M</i> on [<i>a,b</i>], then <i>m(b-a) &leq; L(P,f) &leq; U(P,f) &leq; M(b-a)</i> so that the set of all <i>L(P,f)</i> is a bounded set, and likewise for <i>U(P,f)</i>.  Then the lower and upper integrals are each defined for every bounded function.
      </p>
      <p>
        We now define an integral even more general than the above.  Let <i>&alpha;</i> be a monotonically increasing function on [<i>a,b</i>].  Since <i>&alpha;(a), &alpha;(b)</i> are both finite then <i>&alpha;</i> is bounded.  We define

        $$ \Delta \alpha_i = \alpha(x_i) - \alpha(x_{i-1}) $$

        $$ U(P,f,\alpha) = \sum_{i=1}^n \left(\sup_{x_{i-1}< x < x_i}f(x)\right)\Delta \alpha_i $$

        and likewise for <i>L(P,f,&alpha;)</i>.  We call the <b>upper Riemann-Stieltjes integral</b>

        $$ \overline{\int_a^b}f\ d\alpha = \inf_{P}U(P,f,\alpha) $$

        and likewise for the <b>lower Riemann-Stieltjes integral</b>.  When these last two are equal we write

        $$ \int_a^b f\ d\alpha $$

        for their common value, called the <b>Riemann-Stieltjes integral</b>.  When this exists we write <i>f &in; &#x211C;(&alpha;)</i> and say that <i>f</i> is integrable (in the Riemann sense) with respect to <i>&alpha;</i>.  When <i>&alpha;(x) = x</i> it is clear that the Riemann integral is a special case of the Riemann-Stieltjes.
      </p>
      <p>
        A partion <i>P<sup>*</sup></i> is a <b>refinement</b> of the partition <i>P</i> if <i>P<sup>*</sup> &supseteq; P</i>.  Given two refinements, <i>P<sub>1</sub>, P<sub>2</sub></i> we call <i>P<sup>*</sup> = P<sub>1</sub> &cup; P<sub>2</sub></i> their <b>common refinement</b>.
      </p>
      <h3>Theorem: If <i>P<sup>*</sup></i> is a refinement of <i>P</i> then the lower and upper sums of the refinement are tighter.  (I.e. \(L(P,f,\alpha)\leq L(P^*,f,\alpha)\leq \underline{\int_a^b} f\ d\alpha \) and likewise for the upper.) </h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> Trivially every one of these sums is bounded by the supremum (assuming the set is bounded, which is guaranteed by <i>f</i> being bounded).  I just wanted to throw that in to make evocative how I use "tight" to mean a tight approximation to the lower integral.
        </p>
        <p>
          The proof is by induction on the number of extra points in <i>P<sup>*</sup></i>, so we begin by supposing there is only one extra point, call it <i>x<sup>*</sup></i> and suppose <i>x<sup>*</sup> &in; (<i>x<sub>i-1</sub></i>,<i>x<sub>i</sub></i>)</i>. (If it were on an end-point it would not be a new point and there would be nothing to prove.)  Then for each index <i>j < i</i>, the terms in <i>L(P,f,&alpha;)</i> and <i>L(P<sup>*</sup>,f,&alpha;)</i> are identical.  A similar, though slightly more complicated statement, can be made for indices greater than <i>i</i> (you just have to take care because the additional point in <i>P<sup>*</sup></i> causes a so-to-speak re-indexing of the points above <i>i</i>).  The important point is that we only need to show that

          $$ \left(\sup_{x_{i-1} < x < x_i}f(x)\right)\Delta x_i \leq \left( \sup_{x_{i-1}< x < x^*}f(x)\right)(x^*-x_{i-1}) + \left( \sup_{x^*< x < x_i}f(x)\right)(x_i-x^*) $$

          Of course the relationship between <i>&Delta;x<sub>i</sub></i> and <i>x<sup>*</sup>-x<sub>i-1</sub>, x<sub>i</sub>-x<sup>*</sup></i> is that <i>&Delta;x<sub>i</sub> = x<sup>*</sup>-x<sub>i-1</sub> + x<sub>i</sub>-x<sup>*</sup></i>.  And of course we can plug that in to <i>(sup<sub>x<sub>i-1</sub> < x < x<sub>i</sub></sub>f(x))&Delta;x<sub>i</sub></i> and distribute.  Combine with the straight-forward fact that the sup over a subset is smaller than the sup over a superset.
        </p>
      </div>
      <h3>Theorem: Lower integrals are always smaller than upper integrals.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> We show that the lower integral &#10780;<i> f d&alpha;</i> is a lower-bound on the set of all upper sums <i>U(P,f,&alpha;)</i>, from which the theorem will immediately result. (The choice to focus on the lower integral first is arbitrary, and a nearly identical proof can use the upper integral.)  That the lower integral is such a lower bound will result if we show that every upper sum is an upper-bound on every lower sum.
        </p>
        <p>
          To show that every upper sum is an upper-bound on every lower sum, we consider arbitary partitions <i>P<sub>1</sub>, P<sub>2</sub></i> and show <i>L(P<sub>1</sub>,f,&alpha;) &leq; U(P<sub>2</sub>,f,&alpha;)</i>.  We then use their common refinement to get

          $$ L(P_1,f,\alpha) \leq L(P^*,f,\alpha) $$
          $$ U(P^*,f,\alpha) \leq U(P_2,f,\alpha) $$

          from the theorem above, and so it only remains to show <i>L(P<sup>*</sup>,f,&alpha;) &leq; U(P<sup>*</sup>,f,&alpha;)</i>.  But this follows since term-by-term the sum on the left has smaller terms than the sum on the right--and this is because the inf over any set is never bigger than the sup.
        </p>
      </div>
      <h3>Theorem: Being integrable is equivalent to the difference between upper and lower sums becoming arbitrarily small.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> The claim is that <i>f &in; &#x211C;(&alpha;)</i> on [<i>a,b</i>] if and only if for every <i>&epsilon; &in; &Ropf;<sup>+</sup></i> there exists a partition <i>P</i> such that

          $$ U(P,f,\alpha) - L(P,f,\alpha) < \varepsilon $$
        </p>
        <p>
          For the forward direction, by the inf and sup definitions of the lower and upper integrals, there must be partitions <i>P<sub>1</sub>, P<sub>2</sub></i> such that

          $$ L(P_1,f,\alpha) < \underline{\int_a^b} f\ d\alpha - \varepsilon/2 $$
          $$ \overline{\int_a^b}f\ d\alpha + \varepsilon/2 < U(P_2,f,) $$

          We then of course take the common refinement, and then a chain of familiar inequalities, together with those above, entail the desired result for this common refinement.
        </p>
        <p>
          For the converse, we can show that the difference between the upper and lower integrals is non-negative and smaller than every positive number, and hence must be 0.  That it is non-negative has, from earlier results, effectively already been established.  For any positive &epsilon; we have some <i>P</i> such that

          $$ U(P,f,\alpha) - L(P,f,\alpha) < \varepsilon $$

          Now round the upper sum down to the upper integral, and the lower sum up to the lower integral.
        </p>
      </div>
      <h3>Theorem: For any <i>&epsilon; &in; &Ropf;<sup>+</sup></i> and corresponding <i>P</i> such that <i>U(P,f,&alpha;)-L(P,f,&alpha;) < &epsilon;</i>, then for each [<i>x<sub>i-1</sub>,x<sub>i</sub></i>] and corresponding <i>s<sub>i</sub>,t<sub>i</sub> &in; [x<sub>i-1</sub>,x<sub>i</sub>]</i>, we get

      $$ \sum |f(s_i)-f(t_i)|\Delta \alpha_i < \varepsilon $$

      Also,

      $$ \left| \sum f(t_i)\Delta \alpha_i - \int_a^b f \ d\alpha \right| < \varepsilon $$
      </h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> The first is of course a term-by-term replacement in the difference between any upper- and lower-sum for a partition satisfying the assumption.  The second follows from

          $$ L(P,f,\alpha) \leq \sum f(t_i)\Delta \alpha_i \leq U(P,f,\alpha) $$

          which is due to a term-by-term analysis, and

          $$ L(P,f,\alpha) \leq \int_a^b f\ d\alpha \leq U(P,f,\alpha) $$

          which follows from the definitions in terms of sup and inf.
        </p>
      </div>
      <h3>Theorem: All continuous real functions are integrable on [<i>a,b</i>] with respect to any &alpha;</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> We will use the machinery developed above to show that for any <i>&epsilon; &in; &Ropf;<sup>+</sup></i> there is some partition <i>P</i> such that <i>U(P,f,&alpha;)-L(P,f,&alpha;) < &epsilon;</i>.  Since this difference is <i>&sum;(sup<sub>i</sub>-inf<sub>i</sub>)&Delta;&alpha;<sub>i</sub></i> we try to find a term-by-term over-estimate of <i>sup<sub>i</sub>-inf<sub>i</sub></i>.  (Here <i>sup<sub>i</sub></i> refers to the sup of <i>f</i> over the <i>i</i>th interval, likewise for <i>inf<sub>i</sub></i>.)  This means finding a partition such that it breaks up the interval into regions where the function values are never very far apart throughout the interval.
        </p>
        <p>
          In fact, if you squint hard, this kind of sounds like uniform continuity.  We want to find a sufficiently small <i>&delta; &in; &Ropf;<sup>+</sup></i> such that in <i>|x-y| < &delta;</i> the function values stay small, <i>|f(x)-f(y)| < &epsilon;</i>.  Luckily we assumed <i>f</i> is continuous, and we already know that functions continuous on a closed interval are uniformly continuous.  The hitch is that we don't want <i>&epsilon;</i> to be the bound on these intervals.  Each interval should be bounded by some <i>&eta;</i> such that <i>sup<sub>i</sub>-inf<sub>i</sub> < &eta;</i> and in turn

          $$ \sum \eta\Delta \alpha_i = \eta \sum \Delta \alpha_i = \eta (\alpha(b)-\alpha(a)) < \varepsilon $$

          Since a choice of such an <i>&eta;</i> must exist such that <i>&eta;(&alpha;(b)-&alpha;(a)) < &epsilon;</i>, we use this to define the choice of <i>&eta;</i>.  We then use uniform continuity to choose <i>&delta;</i> such that for all <i>x, y &in; [a,b]</i> we have that if <i>|x-y| < &delta;</i> then <i>|f(x)-f(y)| < &epsilon;</i>.  We then pick a partition such that the distance between adjacent points is never more than <i>&delta;</i>.  With all of this in places the proof that <i>U(P,f,&alpha;)-L(P,f,&alpha;) < &epsilon;</i> follows through some inequalities that we've already planned out.
        </p>
      </div>
      <h3>Theorem: If <i>f</i> is monotonic and <i>&alpha;</i> is continuous then <i>f &in; &#x211C;(&alpha;)</i>.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> This is an interesting interchange of the previous theorem, where we assumed <i>f</i> was continuous and <i>&alpha;</i> is always assumed to be monotonically increasing.  Again for each <i>&epsilon; &in; &Ropf;<sup>+</sup></i> we seek a partition <i>P</i> such that <i>U(P,f,&alpha;)-L(P,f,&alpha;) < &epsilon;</i>.  This time we focus on how a fine enough partition can make <i>&Delta;&alpha;<sub>i</sub></i> small, again using the fact that continuity on a compact set implies uniform continuity.  In particular it is convenient to take every <i>&Delta;&alpha;<sub>i</sub></i> to be of the same size <i>d</i>, so that

          $$ U(P,f,\alpha) - L(P,f,\alpha) = \sum (\sup_i-\inf_i)d = d\sum (\sup_i-\inf_i) = d(f(b)-f(a)) $$

          To make <i>&Delta;&alpha;<sub>i</sub> = d</i> with <i>d</i> small enough, we split up the distance <i>&alpha;(b)-&alpha;(a)</i> into <i>n</i> equal-sized pieces, taking <i>n</i> to be any natural number such that

          $$ d = \frac{\alpha(b)-\alpha(a)}{n} < \varepsilon/(f(b)-f(a)) $$

          Such a partition exists because <i>&alpha;</i> is continuous and therefore has the IVP.  Hence we can choose the first <i>&alpha;(x<sub>1</sub>)</i> to have exactly this value, and then <i>&alpha;(x<sub>2</sub>)</i> to have twice this value, and so on.
        </p>
      </div>
      <h3>Theorem: If <i>f</i> is bounded on <i>[a,b]</i> and has only finitely many discontinuities, and <i>&alpha;</i> is continuous where <i>f</i> is discontinuous, then <i>f &in; &#x211C;(&alpha;)</i>.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> Of course we will find a partition such that the now-familiar condition holds (difference in upper- and lower-sum less than <i>&epsilon;</i>).  Of course the problem-spots of <i>f</i>, we will cover with an interval on which <i>&alpha;</i> helps paper over this difficulty.  Namely for any discontinuity <i>x<sub>j</sub></i> of <i>f</i>, we choose <i>u<sub>j</sub>, v<sub>j</sub></i> such that <i>x<sub>j</sub> &in; (u<sub>j</sub>, v<sub>j</sub>)</i> and the sum over all <i>&alpha;(v<sub>j</sub>)-&alpha;(u<sub>j</sub>)</i> is less than <i>&epsilon;</i>.  This is possible because the continuity of <i>&alpha;</i> implies that we can make each of the <i>n</i> instances of <i>&alpha;(v<sub>j</sub>)-&alpha;(u<sub>j</sub>)</i> each have size less than <i>&epsilon;/n</i>.
        </p>
        <p>
          On the parts of <i>[a, b]</i> not covered by the <i>(u<sub>j</sub>, v<sub>j</sub>)</i>, <i>f</i> is continuous and therefore (since this collection of intervals is compact) uniformly continuous.  On these intervals, employ the methods of two theorems ago.  Use <i>&delta;</i> such that for all <i>s, t</i> in these intervals, <i>|s-t| < &delta;</i> implies <i>|f(s)-f(t)| < &epsilon;</i>.  Make (finite) choices of points in these intervals such that adjacent points are never more than <i>&delta;</i> apart.
        </p>
        <p>
          We've now made all of the choices of points which go into <i>P</i>.  When you expand <i>U(P,f,&alpha;)</i> each interval can be over-estimated either by one or the other of these cases.  For the intervals built around discontinuities of <i>f</i>, over-estimate <i>sup<sub>i</sub>-inf<sub>i</sub></i> with <i>2M</i> where <i>M</i> is the bound on <i>f</i>.  The over-estimate that results is a multiple of <i>&epsilon;</i> and therefore becomes arbitrarily small as <i>&epsilon;</i> is chosen small.
        </p>
      </div>
      <h3>Theorem: A continuous function composed with a bounded integrable function is integrable.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> Suppose <i>f</i> is bounded and integrable, <i>&phi;</i> continuous on the range of <i>f</i>.  Moreover, the range of <i>f</i> must lie inside of some <i>[m,M]</i> on which we assume <i>&varphi;</i> is continuous (and hence uniformly continuous).
        </p>
        <p>
          Since <i>f</i> is integrable we'll try to leverage the partition which exists for it.  In fact, this will be exactly the partition which witnesses the claim.  We hope that the values of <i>f</i> will be close enough together that the "<i>&delta;</i>-condition" given by uniform continuity of <i>&phi;</i> will be satisfied.  However, no such guarantee is possible.
        </p>
        <p>
          Therefore on intervals where that fails, we will bound <i>sup<sub>i</sub>-inf<sub>i</sub></i> for <i>&phi;</i> by the roughest possible bound.  Setting <i>K = sup<sub>t &in; [m,M]</sub>|&phi;(t)|</i> it then must hold that <i>sup<sub>i</sub>-inf<sub>i</sub> &leq; 2K</i>.  If this bound is rough then we must get away with it by putting a tight bound on the partition so that <i>&Delta;&alpha;<sub>i</sub></i> is small enough to compensate.  In fact it will be convenient if we choose

          $$ U(P,f,\alpha)-L(P,f,\alpha) < \delta^2 $$

          This entails that on any interval where <i>f</i> takes values far apart, i.e. where <i>sup<sub>i</sub>f - inf<sub>i</sub>f &geq; &delta;</i>, we can show that <i>&sum; &Delta;&alpha;<sub>i</sub> < &delta;</i>. (Note that the sum is only taken over the intervals where <i>f</i> takes values far apart.)  This follows from the equation above if we expand the left as a sum over differences of sups and infs, which round down to <i>&delta;</i>.  This is how we deliver on the attempt to make <i>&Delta;&alpha;<sub>i</sub></i> being small, as we desired above.
        </p>
        <p>
          But notice that the above is what actually defines the choice of <i>P</i> for which we claim that the integrability criteria is satisfied.  On those intervals where <i>sup<sub>i</sub>f - inf<sub>i</sub>f &geq; &delta;</i>, we can reason that

          $$ \sum (\sup_ih-\inf_ih)\Delta \alpha_i \leq \sum 2K\Delta\alpha_i < 2K\delta $$

          Since we want this to become arbitrarily small, it now makes sense that we should have all along required <i>&delta; < &epsilon;</i>.  We can enforce that now with no change to anything above.
        </p>
        <p>
          The above handles the case where uniform continuity could not be relied upon.  The remaining case is more obvious.  In both cases we get an upper bound which is a multiple of <i>&epsilon;</i>.
        </p>
      </div>
    </div>

    <h2>Section 2</h2>
    <h2>Properties of the Integral</h2>

    <div>
      <h3>Theorem: The familiar algebra of integrals holds.  Linearity, small functions have small integrals, splitting the bounds, ML bound.  Additionally, the "measure" of the integral (<i>&alpha;</i>) is also linear.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> To prove distributivity over sums, i.e. <i>&int;<sub>a</sub><sup>b</sup>(f+g) = &int;<sub>a</sub><sup>b</sup>f + &int;<sub>a</sub><sup>b</sup>g</i>, we show that for any <i>&epsilon; &in; &Ropf;<sup>+</sup></i> we have

          $$ \int(f+g)\ d\alpha \leq U(P, f+g, \alpha) \leq U(P,f,\alpha)+U(P,g,\alpha) < \int f\ d\alpha+\int g\ d\alpha \varepsilon $$

          The first inequation is true for every partition, the second can be verified by an interval-wise rounding <i>sup(f+g) &leq; sup(f) + sup(g)</i>.  The final inequation motivates the choice of partition <i>P</i> such that <i>U(P,f,&alpha;) < &int;f d&alpha; + &epsilon;/2</i> and likewise for <i>g</i>, and the existence of such a choice is obvious (make one choice for each function then take the common refinement).
        </p>
        <p>
          The proof for factoring out constants is even more obvious.
            Small functions have small integrals: by this I mean that if <i>f &leq; g</i> on the interval of integration, then <i>&int; f d&alpha; &leq; &int; g&alpha;</i>.  The proof is obvious by an interval-wise comparison of sups.  Splitting the bounds, i.e. <i>&int;<sub>a</sub><sup>b</sup>f d&alpha; = &int;<sub>a</sub><sup>c</sup>f d&alpha; = &int;<sub>c</sub><sup>b</sup>f d&alpha;</i> follows from merely refining partition at the split point.  The ML bound is that by which, if <i>M = sup|f|</i> over the interval, and <i>L = &alpha;(b)-&alpha;(a)</i>, then <i>&int;<sub>a</sub><sup>b</sup>f d&alpha; &leq; ML</i>.  This follows from rounding every sup interval-wise up to <i>M</i>.
        </p>
        <p>
          Linearity in the "measure" means <i>&int;f d(c&alpha;<sub>1</sub>+&alpha;<sub>2</sub>) = c&int;f d&alpha;<sub>1</sub>+&int;f d&alpha;<sub>2</sub></i>.  This is immediate from factoring constants out of sums and re-grouping sums.
        </p>
      </div>
      <h3>Theorem: The product of integrable functions is always integrable, and the absolute value grows when distributed into an integral.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> We can relate a product to a factorization by way of squares, and use the fact that compositions of integrable functions are integrable to show that the square of a function is integrable.  The factorization is easy to find if we just think about

          $$ (f+g)^2 = f^2+2fg+g^2 $$

          and solve for <i>fg</i>.  The integrability of absolute values follows also by composition.  The inequality follows by the factorization of constant multiples, choosing whichever constant makes the integral positive.  Then apply the fact that bigger functions have bigger integrals.
        </p>
      </div>
      <p>
        Define <i>u<sub>s</sub></i> to be the unit step function centered at <i>s</i>.
        <h3>Theorem: <i>&int;f du<sub>s</sub> = f(s)</i>.</h3>
        <div class="sol">
          <p>
            <i>Explanation:</i> Take any partition and refine it so that it contains <i>x < s</i>.  To the left of <i>x</i>, all terms are 0 because the unit step function is 0.  To the right, other than the partition containing <i>s</i>, the terms are 0 because <i>&Delta;u<sub>s,i</sub> = 0</i>.  On that one interval containing <i>s</i> the sup of the function and the inf become arbitrarily close to <i>f(s)</i> as we choose <i>x</i> close to <i>s</i>.
          </p>
        </div>
        <h3>Theorem: The above generalizes to any countable collection of points, even when the unit step functions have non-negative coefficients so long as the series of coefficients converges.  I.e. <i>&int;<sub>a</sub><sup>b</sup>f (d&sum;u<sub>c<sub>n</sub></sub>) = &sum;c<sub>n</sub>f(s<sub>n</sub>)</i>.</h3>
        <div class="sol">
          <p>
            <i>Explanation:</i> Since <i>&sum;u<sub>c<sub>n</sub></sub> &leq; &sum;c<sub>n</sub> < &infin;</i> we know that the series on the left point-wise converges at each <i>x</i>.  It is also clear that as a function of <i>x</i> it is monotonically increasing.  To show the rest, we show that the limit of the partial sums is the integral, in particular by showing that the absolute difference becomes arbitrarily small.  To that end select any <i>&epsilon; &in; &Ropf;</i> and choose a large enough index <i>N</i> such that the tail of the sum is less than <i>&epsilon;</i>.  Split the sum into those parts before and after this index and use the linearity of the "measure".  Clearly the integral over the finite sum measure becomes a finite sum.  For the infinite sum, apply the <i>ML</i> bound and notice that <i>L = &alpha;(b)-&alpha;(a) = &sum;<sub>n=N</sub><sup>&infin;</sup>u<sub>s<sub>n</sub></sub>(b)-0 &leq; &sum;c<sub>n</sub> < &epsilon;</i>.
          </p>
        </div>
      </p>
      <h3>Theorem: <i>&int;f d&alpha; = &int;f&alpha;' dx</i> where the prime mark here means the derivative.</h3>
      <div class="sol question">
        <p>
          <i>Explanation:</i> We show that each side of the equation has the same upper integral, i.e. \(\overline\int_a^b f \ d\alpha = \overline \int_a^b f(x)\alpha'(x)\ dx\) by showing

          $$ U(P,f,\alpha) \leq U(P,f\alpha') + \varepsilon $$

          for each <i>&epsilon; &in; &Ropf;<sup>+</sup></i> and some partition <i>P</i>.  The proof in the other direction will be the same, and a proof that the lower integrals are equal is again the same.
        </p>
        <p>
          As an observation before getting into the proof, notice that in <i>U(P,f&alpha;')-L(P,f&alpha;')</i> it almost seems that we could factor <i>f</i> out.  Although that's not quite true, what we can do instead is to multiply both sides of <i>U(P,&alpha;')-L(P&alpha;') < &epsilon;</i> by <i>sup|f(x)|</i> and then perhaps use this to "round down" the left-hand-side with <i>f</i>.  This will become part of one step below.
        </p>
        <p>
          So to begin, let <i>P</i> be such that <i>U(P,&alpha;')-L(P,&alpha;') < &epsilon;</i>.  Apply the mean value theorem to find <i>t<sub>i</sub> &in; [x<sub>i-1</sub>,x<sub>i</sub>]</i> such that <i>&Delta;&alpha;<sub>i</sub> = &alpha;'(t<sub>i</sub>)&Delta;x<sub>i</sub></i>.  So

          $$ \sum_{i=1}^n f(s_i)\Delta\alpha_i = \sum_{i=1}^n f(s_i)\alpha'(t_i)\Delta x_i $$

          But also from <i>&Delta;&alpha;<sub>i</sub> = &alpha;'(t<sub>i</sub>)&Delta;x<sub>i</sub></i> it follows from an earlier theorem that if <i>s<sub>i</sub> &in; [x<sub>i-1</sub>,x<sub>i</sub>]</i> then

          $$ \sum_{i=1}^n |\alpha'(s_i) - \alpha(t_i)|\Delta x_i < \varepsilon $$
        </p>
        <p>
          At this point we employ the observation above.

          $$ \sum_{i=1}^n M|\alpha'(s_i)-\alpha'(t_i)|\Delta x_i \leq M\varepsilon $$

          $$ \sum_{i=1}^n |M\alpha'(s_i)-M\alpha'(t_i)|\Delta x_i \leq M\varepsilon $$

          $$ \left|\sum_{i=1}^n M (\alpha'(s_i)-\alpha'(t_i))\Delta x_i)\right| \leq \sum_{i=1}^n |M\alpha'(s_i)-M\alpha'(t_i)|\Delta x_i \leq M\varepsilon $$
        </p>
      </div>
      <h3>Change of Variables Theorem: \(\int_A^B g\ d\beta = \int_a^b f\ d\alpha\) (with the familiar assumptions).</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> Part of the familiar assumptions is that there is some transformation <i>&phi;: [A,B] &rightarrow; [a,b]</i> which is strictly increasing, such that <i>&phi;(A)=a, &phi;(B)=b</i>.  To each partition <i>P</i> of [<i>a,b</i>] there corresponds a partition (using the inverse of <i>&phi;</i>) of [<i>A,B</i>].  Another part of our assumption is that <i>f(&phi;(y))=g(y)</i> and that <i>&beta;(y) = &alpha;(&phi;(y))</i> from which it follows that the values <i>f</i> takes on each interval of <i>P</i> are the same that <i>g</i> takes on each interval of <i>Q</i>.  So the upper sums of each are the same, so are the lower, so the two sets have the same sup and inf and therefore the integrals are equal.
        </p>
      </div>
    </div>

    <h2>Section 3</h2>
    <h2>Integration and Differentiation</h2>

    <div>
      <p>
        We define the <b>area function</b> \(F(x) = \int_a^x f(t) \ dt\).  Correspondingly we'll talk about the <b>boundary function</b> <i>f</i>.
      </p>
      <h3>
        Theorem: The area function of an integrable function is continuous.  If the boundary function is continuous at <i>x</i> then the area function is differentiable there and <i>F'(x)=f(x)</i>.
      </h3>
      <div class="sol question">
        <p>
          <i>Explanation:</i> For any <i>x,y</i> in the interval,

          $$ |F(x)-F(y)| = \left|\int_x^y f(t)\ dt\right| \leq M(y-x) $$

          where the first equality is due to the algebra of integrals, and the second is the ML bound with <i>M</i> a bound on <i>f</i> (which we assume exists for integrable functions).  This will help us to prove continuity:  If <i>|y-x| < &epsilon;M</i> then <i>|F(x)-F(y)| < &epsilon;</i>.
        </p>
        <p>
          Now suppose <i>f</i> is continuous at <i>x<sub>0</sub></i> and for any <i>&epsilon; &in; &Ropf;<sup>+</sup></i>, set <i>&delta;</i> such that <i>|t-x<sub>0</sub>| < &delta;</i> implies that <i>|f(t)-f(x<sub>0</sub>)| < &epsilon;</i>.  We will show that

          $$ \left| \frac{F(t)-F(s)}{t-s} - f(x_0) \right| < \varepsilon $$

          which is to say that the difference quotient goes to <i>f(x<sub>0</sub>)</i>.  But first notice that

          $$ \frac{F(t)-F(s)}{t-s} - f(x_0) = \frac{\int_s^t f(u)\ du}{t-s} - \left(\frac{t-s}{t-s}\right)f(x_0) $$

          $$ = \frac{\int_s^t f(u)\ du - \left(\int_s^t 1\ du\right)f(x_0)}{t-s} = \frac{\int_s^t(f(u)-f(x_0))}{t-s} $$
        </p>
      </div>
      <h3>The Fundamental Theorem of Calculus: If <i>F' = f</i> then \(\int_a^b f(x) dx = F(b) - F(a)\).</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> For any <i>&epsilon; &in; &Ropf;<sup>+</sup></i> choose a partition for <i>f</i>.  Apply the mean-value theorem to the intervals,

          $$ F(x_i)-F(x_{i-1}) = f(t_i)\Delta x_i $$

          so that <i>&sum; f(t<sub>i</sub>)&Delta;x_i = F(b)-F(a)</i>.  By a previous theorem

          $$ \left| \sum_{i=1}^n f(t_i)\Delta \alpha_i - \int_a^b f \ d\alpha \right| < \varepsilon $$
        </p>
      </div>
      <h3>Integration by Parts: \(\int u\ dv = uv - \int v\ du\).</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> Rearrange the formula into a single integral and confirm the boundary function is the derivative of the integrand.  Clearly theorems involving only constant multiples, summation, and differentation still hold.  In particular the Fundamental Theorem of Calculus holds for vectors.
        </p>
      </div>
    </div>

    <h2>Section 4</h2>
    <h2>Integration of Vector-valued Functions</h2>

    <div>
      <p>
        Integration of vector-valued functions goes component-wise. All theorems which involved only scalars, summation, and differentiation still hold.  In particular the Fundamental Theorem of Calculus generalizes to vectors.
      </p>
      <h3>Theorem: \(\left|\int_a^b \vec f \ d\alpha \right| \leq \int_a^b |\vec f|\ d\alpha\)</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> Showing that the integral on the right exists is a simple application of some theorems earlier. To show the inequation, it should evoke some sense that the Schwartz inequality is lurking here.  Indeed, we take some obvious algebraic steps

          $$ \left|\int_a^b \vec f \ d\alpha \right|^2 = \sum \left(\int_a^b f_i\ d\alpha\right)^2 = \int \left(\sum f_i\int f_i \ d\alpha\right) \ d\alpha $$
        </p>
        <p>
          If we're looking for a place to apply the Schwartz inequality then we're looking for a sum of products, and now we have one.  From there the rest is straight-forward algebraic steps.
        </p>
      </div>
    </div>

    <h2>Section 5</h2>
    <h2>Rectifiable Curves</h2>

    <div>
      <p>
        A <b>curve</b> is a continuous mapping of a real interval into <i>&Ropf;<sup>k</sup></i> and we write it as <i>&gamma;</i>. We seek to define a notion of arc-length and toward that goal we define the sum over a bunch of secant segments.

        $$ \Lambda(P,\gamma) = \sum_{i=1}^n | \gamma(x_i) - \gamma(x_{i-1})| $$

        The <b>arclength</b> is the supremum of this over all partitions.  If this is finite we call the curve a <b>rectifiable curve</b>.
      </p>
      <p>
        We call a curve <b>continuously differentiable</b> if its derivative is continuous.
      </p>
      <h3>Theorem: A continuously differentiable curve is rectifiable and

      $$ \Lambda(\gamma) = \int_a^b|\gamma'(t)|\ dt $$</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> First we prove \(\Lambda(\gamma)\leq \int_a^b|\gamma'(t)|\ dt \) by showing that the right-hand side is an upper bound on the secant sum for any partition.  In particular we show that each term in the secant sum is smaller than a corresponding interval of the integral.  That is to say for any interval,

          $$ |\gamma(x_i)-\gamma(x_{i-1})| \leq \int_{x_{i-1}}^{x_i}|\gamma'(t)|\ dt $$

          This follows by first applying the fundamental theorem of calculus on the left-hand side, then using the previous theorem.
        </p>
        <p>
          Next we show \(\int_a^b |\gamma'(t)|\ dt \leq \Lambda(\gamma)\).  Since this is the hard direction we imagine that this may require adding some <i>&epsilon;</i> to something and getting a corresponding partition.  The direction of the inequality tells us that we want to show \(\int_a^b|\gamma'(t)|\ dt \leq \Lambda(\gamma)+\varepsilon\).
        </p>
        <p>
          Now one would naturally guess at this point that we pick a partition such that <i>&Lambda;(P,&gamma;) < &Lambda;(&gamma;) + &epsilon;</i>.  However we will soon see that such a choice would need to get refined down, so rather than doing so, let's start looking at the consideration which would prompt this refinement.  We will, as we often have before, use the fact that <i>&gamma;'</i> is uniformly continuous on [<i>a,b</i>], so let <i>&delta;</i> correspond to <i>&epsilon;</i>.  Now use <i>&delta;</i> to choose a partition such that the distance between the points is smaller than <i>&delta;</i>. Now for any points in the partition <i>&gamma;'</i> stays bounded, i.e.

          $$ |\gamma'(t)|\leq|\gamma'(x_i)|+\varepsilon $$
        </p>
        <p>
          Now with that in hand we can interval-by-inverval show

          $$ \int_{x_{i-1}}^{x_i}|\gamma'(t)|\ dt \leq |\gamma(x_i)-\gamma(x_{i-1})| + 2\varepsilon\Delta x_i $$

          by first using the ML bound with what we established above (this works in a <i>x<sub>i</sub></i>), then reinterpret this back into an integral from <i>x<sub>i-1</sub></i> to <i>x<sub>i</sub></i>, split the sum and use the triangle inequality, reserving one term for the FTC, and the other becomes another <i>&epsilon;&Delta;x<sub>i</sub></i> again by using the ML bound.  
        </p>
      </div>
    </div>


































  </body>
</html>

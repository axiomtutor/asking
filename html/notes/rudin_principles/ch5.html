<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Notes - Rudin Principles Ch5</title>
    <script src="https://d3js.org/d3.v5.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="../notes.css">
  </head>
  <body>
    <h1>Chapter 5</h1>
    <h1>Differentiation</h1>

    <h2>Section 1</h2>
    <h2>The Derivative of a Real Function</h2>

    <div>
      <p>
        If <i>f</i> is a real-valued function on [<i>a,b</i>] then for any \(x\in [a,b]\) we define the <b>derivative at <i>x</i></b> to be the limit of the difference quotient as \(t\to x\).
      </p>
      <h3>Theorem: Differentiability implies continuity.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> We want to show that the limit of the function equals the function value,

          $$ \lim_{t\to x}f(t) = f(x) $$

          which we can rearrange into the difference quotient,

          $$ \lim_{t\to x}(f(t)-f(x)) = 0 $$

          $$ \lim_{t\to x}\left( \frac{f(t)-f(x)}{t-x} \cdot (t-x)\right) = 0 $$
        </p>
        <p>
          Now by our assumption of differentiability, we can distribute the limit to each factor, it becomes \( c\cdot 0 \) for some finite real <i>c</i>.
        </p>
      </div>
      <h3>Theorem: The derivative of a monomial, \(\frac{d}{dx} x^n = nx^{n-1}\)</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> The proof can easily be done by induction.  Alternately, one can use the formula

          $$ t^n - x^n = (t-x)\sum_{i=0}^{n-1}t^{n-1-i}x^i $$

          for a direct proof.  These proof techniques only apply for \( n\in\mathbb N \).  We can again prove a base-case for <i>n=-1</i> and then use induction to obtain this result for all \( n\in \mathbb Z\).
        </p>
      </div>
      <h3>Theorem: The algebra of derivatives is true.</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> That the derivative of a sum is the sum of derivatives is due to the distributivity of limits.  But to find the derivative of a product we have to find

          $$ \lim_{t\to x}\frac{f(t)g(t)-f(x)g(x)}{t-x} = \lim_{t\to x}\frac{f(t)g(t)-f(t)g(x)+f(t)g(x)-f(x)g(x)}{t-x} $$

          where this equality is motivated by the fact that it affords two factorings, one on the left and one on the right.

          $$ = \lim_{t\to x} \frac{f(t)(g(t)-g(x)) + g(x)(f(t)-f(x))}{t-x} $$
        </p>
        <p>
          Now distribute the divisor, then the limit, you get the product rule.
        </p>
        <p>
          The quotient rule follows from the product and chain rules, together with the derivative of a monomial, so we prove the chain rule next.
        </p>
      </div>
      <h3>Theorem: The chain rule, \(\frac{d}{dx}f(g(x))=f'(g(x))g'(x) \).</h3>
      <div class="sol">
        <p>
          <i>Explanation:</i> We need find the limit

          $$ \lim_{t\to x} \frac{f(g(t)) - f(g(x))}{t-x} $$

          A traditionally desired, and nearly correct proof, is to identify that <i>g(t)</i> and <i>g(x)</i> are "the variables" of <i>f</i>, so to get the derivative of <i>f</i> we work these in as if they were the <i>t</i> and <i>x</i> alone.

          $$ =\lim_{t\to x} \frac{f(g(t))-f(g(x))}{t-x}\cdot\frac{g(t)-g(x)}{g(t)-g(x)} = \lim_{t\to x} \frac{f(g(t))-f(g(x))}{g(t)-g(x)}\cdot \frac{g(t)-g(x)}{t-x}$$
        </p>
        <p>
          At this point we are itching to distribute the limit and say that the left is <i>f'(g(x))</i> and the right is <i>g'(x)</i>. Unfortunately, this could be invalid.  <i>g(t)-g(x)</i> could be zero.  In most other cases we are protected from this due to how the limit is defined. Namely, limits by definition specifically omit the choice <i>t=x</i> (and that way of defining the limit is largely motivated by precisely this reason).  But since here we no longer have this guarantee, we must be more careful.
        </p>
        <p>
          So we need to consider two possibilities: We could pick points as \(t\to x\) such that \(g(t)-g(x)\ne 0\), in which case we can use the sequence theorems about limits.  In this case, we are now assured that our itching desire to distribute limits is valid, and the proof from here is easy.  If no such sequence exists, i.e. every sequence as \(t\to x\) must contain some points at which \(g(t)-g(x)=0\) then it must be the case that in fact <i>g(x)</i> is constant on some interval around <i>x</i>.  In that case <i>f(g(x))</i> is constant on the same interval and the derivative must be 0.  In this case the chain rule holds as a special case, as <i>g'(x) = 0</i>.
        </p>
        <p>
          Now in fact Rudin gives an alternate proof that is also elegant and worth-while because it uses a principle we'll later have use for.  I like to start of the introduction of this principle by considering a somewhat natural object, the linearization of <i>f</i>, which we presumably remember from calculus is defined as

          $$ L(x) = f'(a)(x-a)+f(a) $$

          This is also the tangent line to the graph, and is the first-order approximation of <i>f</i>.  As an approximation, it's natural to also study the error, which we could call <i>e</i> and therefore define as

          $$ e(x) = f(x) - L(x) $$
        </p>
        <p>
          Since <i>L</i> is a first-degree polynomial and <i>f</i> is differentiable (therefore continuous), then <i>e</i> is continuous.  Also clearly <i>\lim_{x\to a}e(x)=0</i>.  
        </p>
      </div>
































  </body>
</html>
